\ifx\PREAMBLE\undefined
\input{preamble}
\begin{document}
\fi
\chapter{Stream Ciphers}
First we would like to provide a precise definition for symmetric ciphers.
\begin{definition}\textbf{(Symmetric Cipher)}
A \textbf{cipher} defined over $(\mathcal{K,M,C})$, in which $\mathcal{K}$ is the set of all possible keys, $\mathcal{M}$ is the set of all possible messages and $\mathcal{C}$ is the set of all possible cipher texts, is a pair of efficient algorithms $(E,D)$ in which the encryption algorithm $E:\mathcal{K\times M}\rightarrow\mathcal{C}$ and the decryption algorithm $D:\mathcal{K\times C}\rightarrow \mathcal{M}$ satisfy the consistence equation
\begin{equation*}
D(k,E(k,m))=m, \forall k\in\mathcal{K},m\in\mathcal{M}.
\end{equation*}
\end{definition}
In practice, $E$ is often randomized, while $D$ is always deterministic.
\section{OTP and Perfect Secrecy}
Now we will introduce our first example of a secure cipher, namely \textbf{the one time pad}. In this case, we have $\mathcal{K=M=C=}\{0,1\}^n$. A key is simply a bit string as long as the message to be encrypted. The cipher text is the XOR of the key and the message, i.e.
\begin{equation*}
c\coloneqq E(k,m)= k\oplus m.
\end{equation*}
To decrypt a cipher text, we simply compute the XOR again, i.e.
\begin{equation*}
m\coloneqq E(k,c)= k\oplus c.
\end{equation*}
Since we have $D(k,E(k,m))=k\oplus(k\oplus m)=(k\oplus k)\oplus m=0\oplus m=m$\footnote{XOR is addition mod 2, thus is associative. Also provable using $a\oplus b=a\cdot\bar{b}+\bar{a}\cdot b$.}, obviously the consistence equation is satisfied. Similarly we have $k=m\oplus c$.

Now let's explain why OTP is a ``good'' cipher.
\begin{definition}\textbf{(Perfect Secrecy)}
A cipher $(E,D)$ is said to have \textbf{perfect secrecy} if $\forall m_0,m_1\in\mathcal{M}$ with equal length and $\forall c\in\mathcal{C}$, we have 
\begin{equation*}
Pr(E(k,m_0)=c)=Pr(E(k,m_1)=c),
\end{equation*}
in which $k$ is uniform in $\mathcal{K}: k\xleftarrow{R}\mathcal{K}.$
\end{definition}
This definition means that an attacker cannot tell if the message is $m_0, m_1$ or any other message with equal length given only the cipher text. Thus nothing can be learnt about the message from the cipher text, and the cipher is safe from CT-only attack. 

Since $k=c\oplus m$ for OTP, we have $Pr(E(k,m)=c)=\frac{1}{\lvert\mathcal{K}\rvert},\forall k$. Hence OTP has perfect secrecy. Nonetheless, the key has to be as long as the message, which makes OTP impractical in actual use. 

Unfortunately, it can be proved that a cipher with perfect secrecy must satisfy $\lvert\mathcal{K}\rvert>\lvert\mathcal{M}\rvert$, which means the length of the key is at least as long as that of the message. So such ciphers are actually hard to use in practice.
\section{Stream Ciphers}
In this section we will try to make OTP practical. The idea is to use a pseudo-random key instead of a random key. 
\begin{definition}\textbf{(PRG)}
A \textbf{pseudo-random generator} is a function $G:\{0,1\}^s\rightarrow\{0,1\}^n$, in which $n\gg s$. 
\end{definition}
$\{0,1\}^s$ is called the \textbf{seed space}. A PRG must be efficiently computable by a deterministic algorithm. A \textbf{stream cipher} just substitutes the random key in OTP with a pseudo-random key generated by a PRG, i.e. with a random seed $k\in\{0,1\}^s$, we have
\begin{align*}
c=E(k,m)=m\oplus G(k)\\
m=D(k,m)=c\oplus G(k)
\end{align*}

Obviously a stream cipher cannot have perfect secrecy because the seed is much shorter than the message. Thus we need a different notion of security, and the security of a stream cipher depends on the PRG used. 

If an attacker is able to compute all bits of $G(k)$ according to the first $i$ bits, then the PRG is not safe from CT-only attacks. For example, an email following the SMTP protocol always starts with ``from:'', thus the attacker can obtain a prefix of $G(k)$ according to the cipher text. We should always use \textbf{unpredictable PRGs} as defined below.
\begin{definition}\textbf{(Predictable PRG)}
A PRG $G$ is said to be \textbf{predictable} if $\exists$ efficient algorithm $A$ and $i\in[1,n-1]$ s.t. 
\begin{equation*}
Pr\left(A\left(\left.G(k)\right\vert_{1,\dots,i}\right)=\left.G(k)\right\vert_{i+1}\right)\geq\frac{1}{2}+\epsilon
\end{equation*}
for some non-negligible $\epsilon$. 
\end{definition}
\begin{definition}\textbf{(Unpredictable PRG)}
A PRG is \textbf{unpredictable} if it is not predictable. 
\end{definition}
An example of predictable PRG is the famous \textbf{linear congruential generator}. A seed $r[0]$ is chosen randomly. Then we calculate
\begin{equation*}
r[i]=(a\cdot r[i-1]+b)\bmod p
\end{equation*}
in which $a,b,p$ are parameters. In each iteration a few bits of $r[i]$ is outputted. This PRG is easy to predict. 

A variant is the $random()$ in glibc:
\begin{equation*}
r[i]=(r[i-3]+r[i-31])\%2^{32}
\end{equation*}
and output $r[i]\gg 1$. $random()$ should never be used for cryptography.

A theoretical notion of negligibility is to view $\epsilon$ as a function rather than a scalar. $\epsilon:Z^+\rightarrow R^+$ is non-negligible if $\exists d$ s.t. $\epsilon(\lambda)\geq\frac{1}{\lambda^d}$ is infinitely often, i.e. $\epsilon$ is larger than $\frac{1}{\text{polynomial of }\lambda}$ for many $\lambda$. On the contrary, $\epsilon$ is negligible if $\forall d,\exists \lambda_d$ s.t. $\epsilon(\lambda)\leq\frac{1}{\lambda^d},\forall\lambda\geq\lambda_d.$ For instance, $\frac{1}{2^\lambda}$ is negligible, whilst $\frac{1}{\lambda^{1000}}$ is non-negligible. As a trick example, 
\[\epsilon(\lambda)=\begin{cases}
\frac{1}{2^\lambda}&\text{for odd }\lambda\\
\frac{1}{\lambda^{1000}}&\text{for even }\lambda
\end{cases}\]
is non-negligible.
\section{Attacks on OTP and Stream Ciphers}
\subsection{Two Time Pad}
A pad should not be used more than once, otherwise the encrypted messages shall be decrypted easily. Suppose two messages $m_1,m_2$ are encrypted using the same pad $PRG(k)$:
\begin{align*}
c_1\leftarrow m_1\oplus PRG(k)\\
c_2\leftarrow m_2\oplus PRG(k)
\end{align*}
If an eavesdropper has intercepted the two cipher texts. By calculating their XOR:
\begin{align*}
c_1\oplus c_2&=(m_1\oplus PRG(k))\oplus(m_2\oplus PRG(k))\\
&=m_1\oplus(PRG(k)\oplus PRG(k))\oplus m_2\\
&=m_1\oplus 0\oplus m_2=m_1\oplus m_2
\end{align*}
The English language and the ASCII encoding has enough redundancy so that $m_1$ and $m_2$ can be easily decoded from $m_1\oplus m_2$. Examples of the use of two time pads are not rare in the real world. In network traffic, if the same key is used for different sessions, as was the case in MS-PPTP and 802.11b WEP, the encryption will be unsafe. Instead, a new key should be used for each session, which is implemented by TLS. And typically it is not wise to use a stream cipher for disk encryption, because once a file is changed, an attacker can easily know where the change happened. 
\subsection{No Integrity}
In general, OTP and stream ciphers provide no integrity at all. In other words, they are \textbf{malleable}. An attacker can modify the cipher text without being noticed by the receiver. In particular, since $(m\oplus k)\oplus p=(m\oplus p)\oplus k$, an attacker can impose a specific effect on the cipher text (i.e. XOR with a specific $p$).
\section{PRG Security}
Let $G:\mathcal{K}\rightarrow\{0,1\}^n$ be a PRG. We will define what it means when we say that the output of $G$ on a random key is indistinguishable from the output of a truly random sampler on $\{0,1\}^n$.
\begin{definition}\textbf{(Statistical Test)}
A \textbf{statistical test} is an algorithm $A$ on $\{0,1\}^n$ that outputs 0 or 1. 
\end{definition}
As a few examples:
\begin{itemize}
\item $A(x)=1$ iff $\lvert\#0(x)-\#1(x)\rvert\leq 10\sqrt{n}$
\item $A(x)=1$ iff $\lvert\#00(x)-\frac{n}{4}\rvert\leq 10\sqrt{n}$
\item $A(x)=1$ iff $max-run-of-0(x)\leq 10\log{n}$\footnote{The expectation of the maximum run of 0 is roughly $\log n$.}
\end{itemize}
\begin{definition}\textbf{(Advantage)}
Let $G:\mathcal{K}\rightarrow\{0,1\}^n$ be a PRG and $A$ be a statistical test. The \textbf{advantage} of $A$ relative to $G$ is defined as 
\[Adv_{PRG}[A,G]=\left\lvert\mathop{Pr}\limits_{k\xleftarrow{R}\mathcal{K}}[A(G(k))=1]-\mathop{Pr}\limits_{r\xleftarrow{R}\{0,1\}^n}[A(r)=1]\right\rvert.\]
\end{definition}
An advantage close to 1 means that $A$ can distinguish the output of $G$ from a random choice, whilst an advantage close to 0 means that $A$ cannot tell the difference. For example, a dummy statistical test that always outputs 0 has 0 advantage for any $G$, meaning it cannot distinguish any PRG from random choice.
\begin{definition}\textbf{(Secure PRG)}
A PRG $G$ is called a \textbf{secure PRG} if $\forall$ efficient statistical test $A$, $Adv_{PRG}[A,G]$ is negligible.
\end{definition}
Note that the requirement of efficiency of the statistical tests is necessary for this definition to be satisfied. Providing a secure PRG will result in a proof of $P\neq NP$, thus we don't know yet if there exist any secure PRGs. 
\begin{theorem}
A secure PRG is unpredictable.
\end{theorem}
\begin{proof}
We will prove its contrapositive, i.e. a predictable PRG is insecure. Recall that a PRG being predictable means the existence of an efficient algorithm $A$ s.t.
\begin{equation*}
Pr\left(A\left(\left.G(k)\right\vert_{1,\dots,i}\right)=\left.G(k)\right\vert_{i+1}\right)\geq\frac{1}{2}+\epsilon
\end{equation*}
for a non-negligible $\epsilon$. We define a statistical test $B(X)$ that outputs 1 iff $A(X|_{1,\dots,i})=X_{i+1}$. For a random choice, the $(i+1)^{th}$ bit is irrelevant from the first $i$ bits, thus $Pr(B(r)=1)=\frac{1}{2}.$ However $Pr(B(G(k))=1)\geq \frac{1}{2}+\epsilon$, hence $Adv_{PRG}[B,G]\geq\epsilon$, which is not negligible and verifies the insecurity of $G$.
\end{proof}
Actually the converse also holds.
\begin{theorem}
An unpredictable PRG is secure.
\end{theorem}
This theorem means that if next-bit predictors cannot distinguish $G$ from random choice, then no statistical test can. 

Finally let's generalize the definition of computationally indistinguishability.
\begin{definition}
Two distributions $P_1$ and $P_2$ over $\{0,1\}^n$ are \textbf{computationally indistinguishable} if $\forall$ efficient statistical test $A$, \[\left\lvert\mathop{Pr}\limits_{x\leftarrow P_1}[A(x)=1]-\mathop{Pr}\limits_{x\leftarrow P_2}[A(x)=1]\right\rvert\] is negligible. Their relation is denoted as 
\[P_1\approx_p P_2.\]
\end{definition}
According to this definition, a PRG is secure if $\{k\xleftarrow{R}\mathcal{K}:G(k)\}\approx_p uniform(\{0,1\}^n).$
\section{Semantic Security}

\ifx\PREAMBLE\undefined
\end{document}
\fi